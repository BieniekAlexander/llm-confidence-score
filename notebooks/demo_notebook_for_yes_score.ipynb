{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053e6e3f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68a380e",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41448e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intall dependencies\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a02ae-c353-4405-8aef-3a91d59cdca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, pipeline, AutoModelForQuestionAnswering, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52753178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd651df",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_yes_no_prompt = lambda context, question, response: f\"\"\"\n",
    "    Context: {context}\\n\n",
    "    Question: {question}\\n\n",
    "    Response: {response}\\n\n",
    "    Based on the given Context and Question, answer this question:\\n\n",
    "    Is the provided Response correct? Answer only Yes or No.\\n\n",
    "    Answer:\\n\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yes_score(outputs, input_length, tokenizer):\n",
    "    generated_tokens = outputs.sequences[:, input_length:]\n",
    "    # 1. find the index (idx) of the first character-based token.\n",
    "    for idx, tok in enumerate(generated_tokens[0]):\n",
    "        next_token_str = tokenizer.decode(tok, skip_special_tokens=True)\n",
    "        n_letters = sum(c.isalpha() for c in next_token_str)\n",
    "        if n_letters != len(next_token_str):\n",
    "            continue\n",
    "        break\n",
    "    # 2a. do preselection on high probabilities (out of 32k tokens)\n",
    "    probs_all = torch.nn.functional.softmax(outputs.logits[idx][0], dim=-1)\n",
    "    indices = torch.argwhere(probs_all > 0.001)\n",
    "    indices = indices[:, -1]\n",
    "    tokens_max = tokenizer.batch_decode(indices, skip_special_tokens=True)\n",
    "    probs_max = probs_all[probs_all > 0.001]\n",
    "    # 2b. find yes/no probabilities\n",
    "    next_token_dict = {str(t): p for t, p in zip(tokens_max, probs_max)}\n",
    "    yes_prob = next_token_dict.get(\"Yes\", 0.)\n",
    "    no_prob = next_token_dict.get(\"No\", 0.)\n",
    "    # 3. calculate and return yes/no confidence score\n",
    "    yes_score = yes_prob / (yes_prob + no_prob) if yes_prob != 0 or no_prob != 0 else 0.5\n",
    "    return yes_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(scores, title):\n",
    "    plt.hist(scores, range=(0, 1.0), bins=50)\n",
    "    plt.xlabel(\"Yes Score\")\n",
    "    plt.ylabel(\"Number of Questions\")\n",
    "    plt.title(title)\n",
    "    # plt.savefig(f\"{title}.pdf\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d663db16",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 10 # @param\n",
    "data = load_dataset(\"rajpurkar/squad_v2\", split=f\"train[:{NUM_RECORDS}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2a148-df55-454b-bc4c-cb12bb2841ab",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b0c99-eb93-4271-b0a5-90a9c709695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_model_name = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "llama_model = LlamaForCausalLM.from_pretrained(llama_model_name, device_map=device)\n",
    "llama_tokenizer = LlamaTokenizer.from_pretrained(llama_model_name, device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23285cae-c2fc-41db-8e66-bb66b7f02c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_model_name = \"deepset/roberta-base-squad2\"\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(qa_model_name)\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(qa_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44f0b1a",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8a8f7-d0b2-4838-8bc5-13b93f162383",
   "metadata": {},
   "source": [
    "# scores for accurate answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e43ea-b705-42f7-beb2-0319b02129e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate_scores = []\n",
    "for i, row in tqdm(enumerate(data)):\n",
    "    if len(row['answers']['text']) < 1: break\n",
    "    prompt = get_yes_no_prompt(row['context'], row['question'], row['answers']['text'][0])\n",
    "    input_ids = llama_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    input_length = input_ids.shape[1]\n",
    "    outputs = llama_model.generate(input_ids, output_logits=True, return_dict_in_generate=True, max_new_tokens=5)\n",
    "    yes_score = get_yes_score(outputs, input_length, llama_tokenizer)\n",
    "    accurate_scores.append(yes_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b016580-f919-4869-8828-b28fe35f8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(accurate_scores, \"Histogram of Yes Scores Correct Answers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e605505a-e7d9-4c2f-b23e-456f1e0cadde",
   "metadata": {},
   "source": [
    "# scores for answers given by roberta qa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f425d72-e7d3-4cd6-a03c-65aa44b9dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring -qa\n",
    "qa_scores = []\n",
    "for i, row in tqdm(enumerate(data)):\n",
    "    nlp = pipeline('question-answering', model=qa_model_name, tokenizer=qa_model_name)\n",
    "    QA_input = {'question': row[\"question\"], 'context': row['context']}\n",
    "    response = nlp(QA_input)\n",
    "    prompt = get_yes_no_prompt(row['context'], row['question'], response)\n",
    "    input_ids = llama_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    input_length = input_ids.shape[1]\n",
    "    outputs = llama_model.generate(input_ids, output_logits=True, return_dict_in_generate=True, max_new_tokens=5)\n",
    "    yes_score = get_yes_score(outputs, input_length, llama_tokenizer)\n",
    "    qa_scores.append(yes_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(qa_scores, \"Histogram of Yes Scores Question Answers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
